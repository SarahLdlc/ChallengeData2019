{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "di=pd.read_csv('Training_Input_2dx8C9Q.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 218 entries, ID to X_3_lag_0\n",
      "dtypes: float64(217), int64(1)\n",
      "memory usage: 16.6 MB\n"
     ]
    }
   ],
   "source": [
    "di.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>weight_I_1</th>\n",
       "      <th>weight_I_2</th>\n",
       "      <th>weight_I_3</th>\n",
       "      <th>weight_I_4</th>\n",
       "      <th>weight_I_5</th>\n",
       "      <th>weight_I_6</th>\n",
       "      <th>weight_I_7</th>\n",
       "      <th>I_1_lag_20</th>\n",
       "      <th>I_1_lag_19</th>\n",
       "      <th>...</th>\n",
       "      <th>X_3_lag_9</th>\n",
       "      <th>X_3_lag_8</th>\n",
       "      <th>X_3_lag_7</th>\n",
       "      <th>X_3_lag_6</th>\n",
       "      <th>X_3_lag_5</th>\n",
       "      <th>X_3_lag_4</th>\n",
       "      <th>X_3_lag_3</th>\n",
       "      <th>X_3_lag_2</th>\n",
       "      <th>X_3_lag_1</th>\n",
       "      <th>X_3_lag_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.047398</td>\n",
       "      <td>...</td>\n",
       "      <td>101.383783</td>\n",
       "      <td>102.054669</td>\n",
       "      <td>102.375596</td>\n",
       "      <td>103.148605</td>\n",
       "      <td>103.148605</td>\n",
       "      <td>103.046483</td>\n",
       "      <td>103.075701</td>\n",
       "      <td>103.134043</td>\n",
       "      <td>103.221509</td>\n",
       "      <td>103.338192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.912339</td>\n",
       "      <td>...</td>\n",
       "      <td>100.911142</td>\n",
       "      <td>100.938707</td>\n",
       "      <td>100.993926</td>\n",
       "      <td>101.132016</td>\n",
       "      <td>100.745489</td>\n",
       "      <td>100.524617</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.276090</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.554527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.481681</td>\n",
       "      <td>...</td>\n",
       "      <td>100.373084</td>\n",
       "      <td>100.581716</td>\n",
       "      <td>100.313489</td>\n",
       "      <td>100.790251</td>\n",
       "      <td>101.013756</td>\n",
       "      <td>100.686030</td>\n",
       "      <td>100.686030</td>\n",
       "      <td>100.060233</td>\n",
       "      <td>99.747384</td>\n",
       "      <td>99.970889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.124618</td>\n",
       "      <td>...</td>\n",
       "      <td>100.844136</td>\n",
       "      <td>101.040072</td>\n",
       "      <td>101.055122</td>\n",
       "      <td>101.567682</td>\n",
       "      <td>101.703322</td>\n",
       "      <td>101.974603</td>\n",
       "      <td>101.733422</td>\n",
       "      <td>101.838963</td>\n",
       "      <td>102.080144</td>\n",
       "      <td>101.688272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.665093</td>\n",
       "      <td>99.482389</td>\n",
       "      <td>99.604192</td>\n",
       "      <td>100.030499</td>\n",
       "      <td>99.847797</td>\n",
       "      <td>100.426310</td>\n",
       "      <td>100.426310</td>\n",
       "      <td>100.822217</td>\n",
       "      <td>100.913521</td>\n",
       "      <td>100.852619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.830429</td>\n",
       "      <td>...</td>\n",
       "      <td>101.541742</td>\n",
       "      <td>101.197305</td>\n",
       "      <td>101.771363</td>\n",
       "      <td>102.345411</td>\n",
       "      <td>102.657045</td>\n",
       "      <td>102.919468</td>\n",
       "      <td>102.804653</td>\n",
       "      <td>102.870260</td>\n",
       "      <td>102.952272</td>\n",
       "      <td>102.870260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000927</td>\n",
       "      <td>...</td>\n",
       "      <td>100.638666</td>\n",
       "      <td>100.777561</td>\n",
       "      <td>100.958045</td>\n",
       "      <td>101.110801</td>\n",
       "      <td>100.860827</td>\n",
       "      <td>101.485631</td>\n",
       "      <td>101.152390</td>\n",
       "      <td>101.629304</td>\n",
       "      <td>101.699410</td>\n",
       "      <td>101.965917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.912339</td>\n",
       "      <td>...</td>\n",
       "      <td>100.911142</td>\n",
       "      <td>100.938707</td>\n",
       "      <td>100.993926</td>\n",
       "      <td>101.132016</td>\n",
       "      <td>100.745489</td>\n",
       "      <td>100.524617</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.276090</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.554527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.995851</td>\n",
       "      <td>...</td>\n",
       "      <td>101.009043</td>\n",
       "      <td>100.935945</td>\n",
       "      <td>100.935945</td>\n",
       "      <td>100.175489</td>\n",
       "      <td>100.526470</td>\n",
       "      <td>101.023644</td>\n",
       "      <td>101.696401</td>\n",
       "      <td>101.871892</td>\n",
       "      <td>102.047380</td>\n",
       "      <td>101.959589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.839883</td>\n",
       "      <td>...</td>\n",
       "      <td>101.442465</td>\n",
       "      <td>100.876775</td>\n",
       "      <td>101.796090</td>\n",
       "      <td>101.994037</td>\n",
       "      <td>102.559727</td>\n",
       "      <td>102.489038</td>\n",
       "      <td>101.852659</td>\n",
       "      <td>100.933345</td>\n",
       "      <td>101.103051</td>\n",
       "      <td>102.036487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.580681</td>\n",
       "      <td>...</td>\n",
       "      <td>101.546900</td>\n",
       "      <td>101.859401</td>\n",
       "      <td>101.625001</td>\n",
       "      <td>101.296901</td>\n",
       "      <td>101.281301</td>\n",
       "      <td>101.031300</td>\n",
       "      <td>100.937500</td>\n",
       "      <td>100.703100</td>\n",
       "      <td>100.859401</td>\n",
       "      <td>100.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.475880</td>\n",
       "      <td>...</td>\n",
       "      <td>101.236798</td>\n",
       "      <td>101.251676</td>\n",
       "      <td>101.609297</td>\n",
       "      <td>101.445363</td>\n",
       "      <td>101.490090</td>\n",
       "      <td>101.445363</td>\n",
       "      <td>101.430486</td>\n",
       "      <td>101.147345</td>\n",
       "      <td>100.908930</td>\n",
       "      <td>101.356005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.071616</td>\n",
       "      <td>...</td>\n",
       "      <td>100.765045</td>\n",
       "      <td>100.673196</td>\n",
       "      <td>100.275448</td>\n",
       "      <td>100.397847</td>\n",
       "      <td>101.101592</td>\n",
       "      <td>101.132242</td>\n",
       "      <td>101.254639</td>\n",
       "      <td>101.468789</td>\n",
       "      <td>101.040394</td>\n",
       "      <td>101.468789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.332579</td>\n",
       "      <td>...</td>\n",
       "      <td>101.793799</td>\n",
       "      <td>101.566243</td>\n",
       "      <td>101.499330</td>\n",
       "      <td>102.021354</td>\n",
       "      <td>102.007988</td>\n",
       "      <td>101.592973</td>\n",
       "      <td>102.208813</td>\n",
       "      <td>102.476551</td>\n",
       "      <td>102.181997</td>\n",
       "      <td>102.048171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.987461</td>\n",
       "      <td>...</td>\n",
       "      <td>99.711982</td>\n",
       "      <td>99.510414</td>\n",
       "      <td>99.568018</td>\n",
       "      <td>99.856036</td>\n",
       "      <td>99.654378</td>\n",
       "      <td>99.510414</td>\n",
       "      <td>100.144055</td>\n",
       "      <td>100.921659</td>\n",
       "      <td>101.065714</td>\n",
       "      <td>100.864055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.195631</td>\n",
       "      <td>...</td>\n",
       "      <td>99.170771</td>\n",
       "      <td>99.278537</td>\n",
       "      <td>100.086774</td>\n",
       "      <td>100.113672</td>\n",
       "      <td>99.709596</td>\n",
       "      <td>99.467082</td>\n",
       "      <td>99.925127</td>\n",
       "      <td>100.005907</td>\n",
       "      <td>99.844260</td>\n",
       "      <td>99.871245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.485650</td>\n",
       "      <td>...</td>\n",
       "      <td>98.487620</td>\n",
       "      <td>98.646815</td>\n",
       "      <td>99.575485</td>\n",
       "      <td>98.646815</td>\n",
       "      <td>98.527441</td>\n",
       "      <td>98.076350</td>\n",
       "      <td>98.275364</td>\n",
       "      <td>97.585526</td>\n",
       "      <td>98.182480</td>\n",
       "      <td>98.567260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.746189</td>\n",
       "      <td>...</td>\n",
       "      <td>101.342034</td>\n",
       "      <td>99.985018</td>\n",
       "      <td>100.730666</td>\n",
       "      <td>101.267497</td>\n",
       "      <td>101.520978</td>\n",
       "      <td>101.133314</td>\n",
       "      <td>100.521849</td>\n",
       "      <td>100.313128</td>\n",
       "      <td>99.597353</td>\n",
       "      <td>99.597353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.208498</td>\n",
       "      <td>...</td>\n",
       "      <td>100.274800</td>\n",
       "      <td>99.615279</td>\n",
       "      <td>99.780159</td>\n",
       "      <td>99.890080</td>\n",
       "      <td>99.890080</td>\n",
       "      <td>100.439680</td>\n",
       "      <td>100.906799</td>\n",
       "      <td>101.181599</td>\n",
       "      <td>101.154162</td>\n",
       "      <td>100.631997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.746189</td>\n",
       "      <td>...</td>\n",
       "      <td>101.342034</td>\n",
       "      <td>99.985018</td>\n",
       "      <td>100.730666</td>\n",
       "      <td>101.267497</td>\n",
       "      <td>101.520978</td>\n",
       "      <td>101.133314</td>\n",
       "      <td>100.521849</td>\n",
       "      <td>100.313128</td>\n",
       "      <td>99.597353</td>\n",
       "      <td>99.597353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  weight_I_1  weight_I_2  weight_I_3  weight_I_4  weight_I_5  \\\n",
       "0    0        0.15        0.00        0.05        0.80        0.00   \n",
       "1    1        0.00        0.00        0.00        0.40        0.25   \n",
       "2    2        0.85        0.00        0.00        0.15        0.00   \n",
       "3    3        0.00        0.00        0.70        0.05        0.25   \n",
       "4    4        0.00        0.55        0.05        0.00        0.00   \n",
       "5    5        0.10        0.00        0.00        0.00        0.00   \n",
       "6    6        0.00        0.25        0.00        0.00        0.70   \n",
       "7    7        0.00        0.00        0.15        0.10        0.00   \n",
       "8    8        0.40        0.30        0.00        0.00        0.00   \n",
       "9    9        0.65        0.00        0.00        0.10        0.00   \n",
       "10  10        0.00        0.00        0.35        0.00        0.00   \n",
       "11  11        0.35        0.00        0.00        0.15        0.50   \n",
       "12  12        0.25        0.00        0.00        0.70        0.05   \n",
       "13  13        0.05        0.80        0.00        0.00        0.15   \n",
       "14  14        0.10        0.00        0.00        0.35        0.00   \n",
       "15  15        0.00        0.25        0.75        0.00        0.00   \n",
       "16  16        0.65        0.25        0.00        0.00        0.00   \n",
       "17  17        0.00        0.10        0.00        0.45        0.00   \n",
       "18  18        0.10        0.10        0.00        0.80        0.00   \n",
       "19  19        0.65        0.00        0.25        0.00        0.10   \n",
       "\n",
       "    weight_I_6  weight_I_7  I_1_lag_20  I_1_lag_19     ...       X_3_lag_9  \\\n",
       "0         0.00        0.00       100.0  100.047398     ...      101.383783   \n",
       "1         0.00        0.35       100.0   99.912339     ...      100.911142   \n",
       "2         0.00        0.00       100.0   99.481681     ...      100.373084   \n",
       "3         0.00        0.00       100.0  100.124618     ...      100.844136   \n",
       "4         0.00        0.40       100.0  100.000000     ...       99.665093   \n",
       "5         0.00        0.90       100.0  100.830429     ...      101.541742   \n",
       "6         0.05        0.00       100.0  100.000927     ...      100.638666   \n",
       "7         0.75        0.00       100.0   99.912339     ...      100.911142   \n",
       "8         0.30        0.00       100.0   99.995851     ...      101.009043   \n",
       "9         0.25        0.00       100.0   99.839883     ...      101.442465   \n",
       "10        0.00        0.65       100.0   98.580681     ...      101.546900   \n",
       "11        0.00        0.00       100.0  101.475880     ...      101.236798   \n",
       "12        0.00        0.00       100.0  100.071616     ...      100.765045   \n",
       "13        0.00        0.00       100.0   99.332579     ...      101.793799   \n",
       "14        0.00        0.55       100.0   99.987461     ...       99.711982   \n",
       "15        0.00        0.00       100.0  100.195631     ...       99.170771   \n",
       "16        0.00        0.10       100.0  100.485650     ...       98.487620   \n",
       "17        0.45        0.00       100.0   99.746189     ...      101.342034   \n",
       "18        0.00        0.00       100.0  100.208498     ...      100.274800   \n",
       "19        0.00        0.00       100.0   99.746189     ...      101.342034   \n",
       "\n",
       "     X_3_lag_8   X_3_lag_7   X_3_lag_6   X_3_lag_5   X_3_lag_4   X_3_lag_3  \\\n",
       "0   102.054669  102.375596  103.148605  103.148605  103.046483  103.075701   \n",
       "1   100.938707  100.993926  101.132016  100.745489  100.524617  100.303743   \n",
       "2   100.581716  100.313489  100.790251  101.013756  100.686030  100.686030   \n",
       "3   101.040072  101.055122  101.567682  101.703322  101.974603  101.733422   \n",
       "4    99.482389   99.604192  100.030499   99.847797  100.426310  100.426310   \n",
       "5   101.197305  101.771363  102.345411  102.657045  102.919468  102.804653   \n",
       "6   100.777561  100.958045  101.110801  100.860827  101.485631  101.152390   \n",
       "7   100.938707  100.993926  101.132016  100.745489  100.524617  100.303743   \n",
       "8   100.935945  100.935945  100.175489  100.526470  101.023644  101.696401   \n",
       "9   100.876775  101.796090  101.994037  102.559727  102.489038  101.852659   \n",
       "10  101.859401  101.625001  101.296901  101.281301  101.031300  100.937500   \n",
       "11  101.251676  101.609297  101.445363  101.490090  101.445363  101.430486   \n",
       "12  100.673196  100.275448  100.397847  101.101592  101.132242  101.254639   \n",
       "13  101.566243  101.499330  102.021354  102.007988  101.592973  102.208813   \n",
       "14   99.510414   99.568018   99.856036   99.654378   99.510414  100.144055   \n",
       "15   99.278537  100.086774  100.113672   99.709596   99.467082   99.925127   \n",
       "16   98.646815   99.575485   98.646815   98.527441   98.076350   98.275364   \n",
       "17   99.985018  100.730666  101.267497  101.520978  101.133314  100.521849   \n",
       "18   99.615279   99.780159   99.890080   99.890080  100.439680  100.906799   \n",
       "19   99.985018  100.730666  101.267497  101.520978  101.133314  100.521849   \n",
       "\n",
       "     X_3_lag_2   X_3_lag_1   X_3_lag_0  \n",
       "0   103.134043  103.221509  103.338192  \n",
       "1   100.276090  100.303743  100.554527  \n",
       "2   100.060233   99.747384   99.970889  \n",
       "3   101.838963  102.080144  101.688272  \n",
       "4   100.822217  100.913521  100.852619  \n",
       "5   102.870260  102.952272  102.870260  \n",
       "6   101.629304  101.699410  101.965917  \n",
       "7   100.276090  100.303743  100.554527  \n",
       "8   101.871892  102.047380  101.959589  \n",
       "9   100.933345  101.103051  102.036487  \n",
       "10  100.703100  100.859401  100.968800  \n",
       "11  101.147345  100.908930  101.356005  \n",
       "12  101.468789  101.040394  101.468789  \n",
       "13  102.476551  102.181997  102.048171  \n",
       "14  100.921659  101.065714  100.864055  \n",
       "15  100.005907   99.844260   99.871245  \n",
       "16   97.585526   98.182480   98.567260  \n",
       "17  100.313128   99.597353   99.597353  \n",
       "18  101.181599  101.154162  100.631997  \n",
       "19  100.313128   99.597353   99.597353  \n",
       "\n",
       "[20 rows x 218 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "di=di.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      "ID        10000 non-null int64\n",
      "Target    10000 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 156.3 KB\n"
     ]
    }
   ],
   "source": [
    "do=pd.read_csv('Training_Output_IJhBXtA.csv')\n",
    "do.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "do=do.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.294867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.412364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.517471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target\n",
       "ID           \n",
       "0  -12.007941\n",
       "1    2.294867\n",
       "2    0.652308\n",
       "3    2.412364\n",
       "4    8.517471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4450 entries, 0 to 4449\n",
      "Columns: 218 entries, ID to X_3_lag_0\n",
      "dtypes: float64(217), int64(1)\n",
      "memory usage: 7.4 MB\n"
     ]
    }
   ],
   "source": [
    "dt=pd.read_csv('Testing_Input_dPKY3Rf.csv')\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=dt.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour les 7 séries de 21 jours calculons les perfs quotidiennes qui valent log(valeur/valeur la veille)\n",
    "for i in range(1,8):\n",
    "    for s in range(20):\n",
    "        di['L_'+str(i)+'_lag_'+str(s)]=np.log(di['I_'+str(i)+'_lag_'+str(s)]/di['I_'+str(i)+'_lag_'+str(s+1)])\n",
    "        dt['L_'+str(i)+'_lag_'+str(s)]=np.log(dt['I_'+str(i)+'_lag_'+str(s)]/dt['I_'+str(i)+'_lag_'+str(s+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de même pour les variables macro\n",
    "for i in range(1,4):\n",
    "    for s in range(20):\n",
    "        di['LX_'+str(i)+'_lag_'+str(s)]=np.log(di['X_'+str(i)+'_lag_'+str(s)]/di['X_'+str(i)+'_lag_'+str(s+1)])\n",
    "        dt['LX_'+str(i)+'_lag_'+str(s)]=np.log(dt['X_'+str(i)+'_lag_'+str(s)]/dt['X_'+str(i)+'_lag_'+str(s+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajoutons pour chacun des 7 la moyenne des 21 valeurs (pour aider au calcul de la covariance)\n",
    "# et la moyenne des 5 dernières pour estimer le rendement à venir\n",
    "for i in range(1,8):\n",
    "    di['M20_'+str(i)]=0\n",
    "    dt['M20_'+str(i)]=0\n",
    "    di['M5_'+str(i)]=0\n",
    "    dt['M5_'+str(i)]=0\n",
    "    for s in range(20):\n",
    "        di['M20_'+str(i)]+=di['L_'+str(i)+'_lag_'+str(s)]\n",
    "        dt['M20_'+str(i)]+=dt['L_'+str(i)+'_lag_'+str(s)]\n",
    "    for s in range(5):\n",
    "        di['M5_'+str(i)]+=di['L_'+str(i)+'_lag_'+str(s)]\n",
    "        dt['M5_'+str(i)]+=dt['L_'+str(i)+'_lag_'+str(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et des moyennes des variables macro\n",
    "for i in range(1,4):\n",
    "    di['LX20_'+str(i)]=0\n",
    "    dt['LX20_'+str(i)]=0\n",
    "    di['LX5_'+str(i)]=0\n",
    "    dt['LX5_'+str(i)]=0\n",
    "    for s in range(20):\n",
    "        di['LX20_'+str(i)]+=di['LX_'+str(i)+'_lag_'+str(s)]\n",
    "        dt['LX20_'+str(i)]+=dt['LX_'+str(i)+'_lag_'+str(s)]\n",
    "    for s in range(5):\n",
    "        di['LX5_'+str(i)]+=di['LX_'+str(i)+'_lag_'+str(s)]\n",
    "        dt['LX5_'+str(i)]+=dt['LX_'+str(i)+'_lag_'+str(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculons une valeur de rendement pondéré récent\n",
    "di['R0']=0\n",
    "dt['R0']=0\n",
    "for i in range(1,8):\n",
    "    di['R0']+=di['M5_'+str(i)]*di['weight_I_'+str(i)]\n",
    "    dt['R0']+=dt['M5_'+str(i)]*dt['weight_I_'+str(i)]\n",
    "di['R0']=di['R0']*(252/5)\n",
    "dt['R0']=dt['R0']*(252/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et d'autres un peu moins récentes (ce qui implique de calculer des moyennes 5 décalées)\n",
    "for i in range(1,8):\n",
    "    di['M5_1_'+str(i)]=0\n",
    "    dt['M5_1_'+str(i)]=0\n",
    "    for s in range(5):\n",
    "        di['M5_1_'+str(i)]+=di['L_'+str(i)+'_lag_'+str(s+5)]\n",
    "        dt['M5_1_'+str(i)]+=dt['L_'+str(i)+'_lag_'+str(s+5)]\n",
    "di['R1']=0\n",
    "dt['R1']=0\n",
    "for i in range(1,8):\n",
    "    di['R1']+=di['M5_1_'+str(i)]*di['weight_I_'+str(i)]\n",
    "    dt['R1']+=dt['M5_1_'+str(i)]*dt['weight_I_'+str(i)]\n",
    "di['R1']=di['R1']*(252/5)\n",
    "dt['R1']=dt['R1']*(252/5)\n",
    "\n",
    "for i in range(1,8):\n",
    "    di['M5_2_'+str(i)]=0\n",
    "    dt['M5_2_'+str(i)]=0\n",
    "    for s in range(5):\n",
    "        di['M5_2_'+str(i)]+=di['L_'+str(i)+'_lag_'+str(s+2*5)]\n",
    "        dt['M5_2_'+str(i)]+=dt['L_'+str(i)+'_lag_'+str(s+2*5)]\n",
    "di['R2']=0\n",
    "dt['R2']=0\n",
    "for i in range(1,8):\n",
    "    di['R2']+=di['M5_2_'+str(i)]*di['weight_I_'+str(i)]\n",
    "    dt['R2']+=dt['M5_2_'+str(i)]*dt['weight_I_'+str(i)]\n",
    "di['R2']=di['R2']*(252/5)\n",
    "dt['R2']=dt['R2']*(252/5)\n",
    "\n",
    "for i in range(1,8):\n",
    "    di['M5_3_'+str(i)]=0\n",
    "    dt['M5_3_'+str(i)]=0\n",
    "    for s in range(5):\n",
    "        di['M5_3_'+str(i)]+=di['L_'+str(i)+'_lag_'+str(s+3*5)]\n",
    "        dt['M5_3_'+str(i)]+=dt['L_'+str(i)+'_lag_'+str(s+3*5)]\n",
    "di['R3']=0\n",
    "dt['R3']=0\n",
    "for i in range(1,8):\n",
    "    di['R3']+=di['M5_3_'+str(i)]*di['weight_I_'+str(i)]\n",
    "    dt['R3']+=dt['M5_3_'+str(i)]*dt['weight_I_'+str(i)]\n",
    "di['R3']=di['R3']*(252/5)\n",
    "dt['R3']=dt['R3']*(252/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculons une estimation de la volatilité du portefeuille\n",
    "# ce serait mieux en matriciel mais comme de toute facon ça va vite....\n",
    "# essayons d'expliciter les covariances des stratégies, qu'on va garder dans le modèle\n",
    "di['vol']=0\n",
    "dt['vol']=0\n",
    "for i in range(1,8):\n",
    "    for j in range(1,8):\n",
    "        di['covL_'+str(i)+'_'+str(j)]=0\n",
    "        dt['covL_'+str(i)+'_'+str(j)]=0\n",
    "        a=252*di['weight_I_'+str(i)]*di['weight_I_'+str(j)]\n",
    "        b=252*dt['weight_I_'+str(i)]*dt['weight_I_'+str(j)]\n",
    "        for s in range(20):\n",
    "            di['covL_'+str(i)+'_'+str(j)]+=(di['L_'+str(i)+'_lag_'+str(s)]-di['M20_'+str(i)])*(di['L_'+str(j)+'_lag_'+str(s)]-di['M20_'+str(j)])\n",
    "            dt['covL_'+str(i)+'_'+str(j)]+=(dt['L_'+str(i)+'_lag_'+str(s)]-dt['M20_'+str(i)])*(dt['L_'+str(j)+'_lag_'+str(s)]-dt['M20_'+str(j)])\n",
    "        di['vol']+=a*di['covL_'+str(i)+'_'+str(j)]\n",
    "        dt['vol']+=b*dt['covL_'+str(i)+'_'+str(j)]\n",
    "di['vol']=np.sqrt(di['vol'])\n",
    "dt['vol']=np.sqrt(dt['vol'])\n",
    "di.vol[di.vol<0.005]=0.005\n",
    "dt.vol[dt.vol<0.005]=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et un ratio de sharpe\n",
    "di['sharpe']=di['R0']/di['vol']\n",
    "dt['sharpe']=dt['R0']/dt['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "di['sharpe1']=di['R1']/di['vol']\n",
    "dt['sharpe1']=dt['R1']/dt['vol']\n",
    "di['sharpe2']=di['R2']/di['vol']\n",
    "dt['sharpe2']=dt['R2']/dt['vol']\n",
    "di['sharpe3']=di['R3']/di['vol']\n",
    "dt['sharpe3']=dt['R3']/dt['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajoutons des covariances des variables macro avec les stratégies \n",
    "for i in range(1,4):\n",
    "    for j in range(1,8):\n",
    "        di['covXI_'+str(i)+'_'+str(j)]=0\n",
    "        dt['covXI_'+str(i)+'_'+str(j)]=0\n",
    "        for s in range(20):\n",
    "            di['covXI_'+str(i)+'_'+str(j)]+=(di['LX_'+str(i)+'_lag_'+str(s)]-di['LX20_'+str(i)])*(di['L_'+str(j)+'_lag_'+str(s)]-di['M20_'+str(j)])\n",
    "            dt['covXI_'+str(i)+'_'+str(j)]+=(dt['LX_'+str(i)+'_lag_'+str(s)]-dt['LX20_'+str(i)])*(dt['L_'+str(j)+'_lag_'+str(s)]-dt['M20_'+str(j)])\n",
    "\n",
    "#et entre elles\n",
    "for i in range(1,4):\n",
    "    for j in range(1,4):\n",
    "        di['covX_'+str(i)+'_'+str(j)]=0\n",
    "        dt['covX_'+str(i)+'_'+str(j)]=0\n",
    "        for s in range(20):\n",
    "            di['covX_'+str(i)+'_'+str(j)]+=(di['LX_'+str(i)+'_lag_'+str(s)]-di['LX20_'+str(i)])*(di['LX_'+str(j)+'_lag_'+str(s)]-di['LX20_'+str(j)])\n",
    "            dt['covX_'+str(i)+'_'+str(j)]+=(dt['LX_'+str(i)+'_lag_'+str(s)]-dt['LX20_'+str(i)])*(dt['LX_'+str(j)+'_lag_'+str(s)]-dt['LX20_'+str(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajoutons des estimations du ratio de Sharpe de chaque stratégie\n",
    "# nous avons calculé plus haut les variances des stratégies : ce sont leurs covariance avec elles memes : covL_i_i\n",
    "# on a calculé aussi plus haut les rendements de chaque stratégie \n",
    "# on applique ici la formule : \n",
    "for i in range(1,8):\n",
    "    di['sha_'+str(i)]=np.sqrt(di['covL_'+str(i)+'_'+str(i)])\n",
    "    di['sha_'+str(i)][di['sha_'+str(i)]<0.005]=0.005\n",
    "    di['sha_'+str(i)]=di['M5_'+str(i)]/di['sha_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,8):\n",
    "    dt['sha_'+str(i)]=np.sqrt(dt['covL_'+str(i)+'_'+str(i)])\n",
    "    dt['sha_'+str(i)][dt['sha_'+str(i)]<0.005]=0.005\n",
    "    dt['sha_'+str(i)]=dt['M5_'+str(i)]/dt['sha_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_I_1</th>\n",
       "      <th>weight_I_2</th>\n",
       "      <th>weight_I_3</th>\n",
       "      <th>weight_I_4</th>\n",
       "      <th>weight_I_5</th>\n",
       "      <th>weight_I_6</th>\n",
       "      <th>weight_I_7</th>\n",
       "      <th>I_1_lag_20</th>\n",
       "      <th>I_1_lag_19</th>\n",
       "      <th>I_1_lag_18</th>\n",
       "      <th>...</th>\n",
       "      <th>covX_3_1</th>\n",
       "      <th>covX_3_2</th>\n",
       "      <th>covX_3_3</th>\n",
       "      <th>sha_1</th>\n",
       "      <th>sha_2</th>\n",
       "      <th>sha_3</th>\n",
       "      <th>sha_4</th>\n",
       "      <th>sha_5</th>\n",
       "      <th>sha_6</th>\n",
       "      <th>sha_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.047398</td>\n",
       "      <td>100.058480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006400</td>\n",
       "      <td>-0.043773</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>-0.324101</td>\n",
       "      <td>-0.197429</td>\n",
       "      <td>-0.340886</td>\n",
       "      <td>-0.330984</td>\n",
       "      <td>-0.121968</td>\n",
       "      <td>-0.225663</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.912339</td>\n",
       "      <td>99.960558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>-0.030488</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.200996</td>\n",
       "      <td>0.144249</td>\n",
       "      <td>0.097936</td>\n",
       "      <td>0.171236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.481681</td>\n",
       "      <td>100.199593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.075157</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>-0.049458</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>-0.005402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.124618</td>\n",
       "      <td>100.023384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007502</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>-0.048202</td>\n",
       "      <td>-0.071082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.070314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.407717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>-0.091830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.071936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    weight_I_1  weight_I_2  weight_I_3  weight_I_4  weight_I_5  weight_I_6  \\\n",
       "ID                                                                           \n",
       "0         0.15        0.00        0.05        0.80        0.00         0.0   \n",
       "1         0.00        0.00        0.00        0.40        0.25         0.0   \n",
       "2         0.85        0.00        0.00        0.15        0.00         0.0   \n",
       "3         0.00        0.00        0.70        0.05        0.25         0.0   \n",
       "4         0.00        0.55        0.05        0.00        0.00         0.0   \n",
       "\n",
       "    weight_I_7  I_1_lag_20  I_1_lag_19  I_1_lag_18    ...     covX_3_1  \\\n",
       "ID                                                    ...                \n",
       "0         0.00       100.0  100.047398  100.058480    ...    -0.006400   \n",
       "1         0.35       100.0   99.912339   99.960558    ...     0.001608   \n",
       "2         0.00       100.0   99.481681  100.199593    ...     0.000031   \n",
       "3         0.00       100.0  100.124618  100.023384    ...    -0.007502   \n",
       "4         0.40       100.0  100.000000   99.407717    ...    -0.000464   \n",
       "\n",
       "    covX_3_2  covX_3_3     sha_1     sha_2     sha_3     sha_4     sha_5  \\\n",
       "ID                                                                         \n",
       "0  -0.043773  0.019785 -0.324101 -0.197429 -0.340886 -0.330984 -0.121968   \n",
       "1  -0.030488  0.000689  0.101508  0.200996  0.144249  0.097936  0.171236   \n",
       "2  -0.001515  0.000207  0.075157  0.013944 -0.049458  0.016398 -0.005402   \n",
       "3   0.004345  0.005191  0.005471 -0.048202 -0.071082  0.000000 -0.070314   \n",
       "4   0.005898  0.001512 -0.060883  0.006253 -0.091830  0.000000 -0.361491   \n",
       "\n",
       "       sha_6     sha_7  \n",
       "ID                      \n",
       "0  -0.225663  0.000000  \n",
       "1   0.000000  0.132242  \n",
       "2   0.000000  0.118538  \n",
       "3   0.000000 -0.036426  \n",
       "4   0.000000 -0.071936  \n",
       "\n",
       "[5 rows x 553 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_I_1</th>\n",
       "      <th>weight_I_2</th>\n",
       "      <th>weight_I_3</th>\n",
       "      <th>weight_I_4</th>\n",
       "      <th>weight_I_5</th>\n",
       "      <th>weight_I_6</th>\n",
       "      <th>weight_I_7</th>\n",
       "      <th>I_1_lag_20</th>\n",
       "      <th>I_1_lag_19</th>\n",
       "      <th>I_1_lag_18</th>\n",
       "      <th>...</th>\n",
       "      <th>covX_3_1</th>\n",
       "      <th>covX_3_2</th>\n",
       "      <th>covX_3_3</th>\n",
       "      <th>sha_1</th>\n",
       "      <th>sha_2</th>\n",
       "      <th>sha_3</th>\n",
       "      <th>sha_4</th>\n",
       "      <th>sha_5</th>\n",
       "      <th>sha_6</th>\n",
       "      <th>sha_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.140550</td>\n",
       "      <td>0.142910</td>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.144630</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.141590</td>\n",
       "      <td>0.146665</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.003208</td>\n",
       "      <td>100.041611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>3.584479e-07</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>-0.002211</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>-0.006210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240925</td>\n",
       "      <td>0.240067</td>\n",
       "      <td>0.237449</td>\n",
       "      <td>0.243864</td>\n",
       "      <td>0.242209</td>\n",
       "      <td>0.238771</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346536</td>\n",
       "      <td>0.464667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>6.233312e-02</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.193864</td>\n",
       "      <td>0.184704</td>\n",
       "      <td>0.248823</td>\n",
       "      <td>0.191192</td>\n",
       "      <td>0.194352</td>\n",
       "      <td>0.155456</td>\n",
       "      <td>0.206657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.433199</td>\n",
       "      <td>98.207613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024273</td>\n",
       "      <td>-2.516615e-01</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.827196</td>\n",
       "      <td>-0.671373</td>\n",
       "      <td>-0.767415</td>\n",
       "      <td>-0.752197</td>\n",
       "      <td>-0.631790</td>\n",
       "      <td>-0.676425</td>\n",
       "      <td>-0.781727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.942139</td>\n",
       "      <td>99.888720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-2.309295e-02</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>-0.058453</td>\n",
       "      <td>-0.052631</td>\n",
       "      <td>-0.102010</td>\n",
       "      <td>-0.015449</td>\n",
       "      <td>-0.075446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.105063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.019208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>1.198886e-04</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.095040</td>\n",
       "      <td>100.162662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>1.830956e-02</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.114570</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>0.084274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.475880</td>\n",
       "      <td>101.350831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036252</td>\n",
       "      <td>2.735931e-01</td>\n",
       "      <td>0.125639</td>\n",
       "      <td>0.879322</td>\n",
       "      <td>0.641706</td>\n",
       "      <td>0.933223</td>\n",
       "      <td>0.674251</td>\n",
       "      <td>0.652541</td>\n",
       "      <td>0.482325</td>\n",
       "      <td>0.597580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         weight_I_1    weight_I_2    weight_I_3    weight_I_4    weight_I_5  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.140550      0.142910      0.137655      0.144630      0.146000   \n",
       "std        0.240925      0.240067      0.237449      0.243864      0.242209   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.200000      0.200000      0.200000      0.200000      0.200000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         weight_I_6    weight_I_7  I_1_lag_20    I_1_lag_19    I_1_lag_18  \\\n",
       "count  10000.000000  10000.000000     10000.0  10000.000000  10000.000000   \n",
       "mean       0.141590      0.146665       100.0    100.003208    100.041611   \n",
       "std        0.238771      0.242928         0.0      0.346536      0.464667   \n",
       "min        0.000000      0.000000       100.0     98.433199     98.207613   \n",
       "25%        0.000000      0.000000       100.0     99.942139     99.888720   \n",
       "50%        0.000000      0.000000       100.0    100.000000    100.019208   \n",
       "75%        0.200000      0.200000       100.0    100.095040    100.162662   \n",
       "max        1.000000      1.000000       100.0    101.475880    101.350831   \n",
       "\n",
       "           ...           covX_3_1      covX_3_2      covX_3_3         sha_1  \\\n",
       "count      ...       10000.000000  1.000000e+04  10000.000000  10000.000000   \n",
       "mean       ...           0.000751  3.584479e-07      0.006200     -0.002211   \n",
       "std        ...           0.008989  6.233312e-02      0.011241      0.193864   \n",
       "min        ...          -0.024273 -2.516615e-01      0.000032     -0.827196   \n",
       "25%        ...          -0.003030 -2.309295e-02      0.001070     -0.058453   \n",
       "50%        ...           0.000572  1.198886e-04      0.002825      0.012351   \n",
       "75%        ...           0.003869  1.830956e-02      0.007640      0.087951   \n",
       "max        ...           0.036252  2.735931e-01      0.125639      0.879322   \n",
       "\n",
       "              sha_2         sha_3         sha_4         sha_5         sha_6  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.013794      0.001573      0.008388      0.002151      0.007775   \n",
       "std        0.184704      0.248823      0.191192      0.194352      0.155456   \n",
       "min       -0.671373     -0.767415     -0.752197     -0.631790     -0.676425   \n",
       "25%       -0.052631     -0.102010     -0.015449     -0.075446      0.000000   \n",
       "50%        0.013365      0.008067      0.000000      0.012064      0.000000   \n",
       "75%        0.104341      0.114570      0.068158      0.106972      0.038884   \n",
       "max        0.641706      0.933223      0.674251      0.652541      0.482325   \n",
       "\n",
       "              sha_7  \n",
       "count  10000.000000  \n",
       "mean      -0.006210  \n",
       "std        0.206657  \n",
       "min       -0.781727  \n",
       "25%       -0.105063  \n",
       "50%        0.000000  \n",
       "75%        0.084274  \n",
       "max        0.597580  \n",
       "\n",
       "[8 rows x 553 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objectif est de minimiser la différence entre les f(y) calculés et donnés suivant la norme l1 (la moyenne des valeurs absolues des écarts). Il sera pour cela utile de connaitre les f(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "do['custom']=np.sign(do['Target'])*np.exp(-1/(abs(do['Target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on cherchera à minimiser l'écart absolu moyen (norme l1, pas l'écart quadratique ou le R2) avec ces y transformés "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour modéliser, attention à mettre des séquences temporelles différentes en train et test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l'énoncé indique que chaque séquence est répétée 50 fois donc on a 10 000 / 500 = 200 séquences différentes. Plutôt que de les identifier entièrement (c'est lourd), vérifions si une variable unique ne permet pas de le faire (comme c'est probable), par exemple la 1ère variable économique (X_1_lag_1) ou les rendements quotidiens de cette variable (LX20_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "print(di.X_1_lag_1.nunique(),di.LX20_1.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ça marche!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Muller & Guido \n",
    "# https://github.com/amueller/introduction_to_ml_with_python/blob/master/02-supervised-learning.ipynb\n",
    "\n",
    "def plot_feature_importances(model, Frame):\n",
    "    plt.clf()\n",
    "    n_features=len(Frame.columns)\n",
    "    plt.figure(figsize=(10,100))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), Frame.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réduisons le nombre de variables\n",
    "# supprimons les colonnes initiales (sauf les poids)\n",
    "to_drop=di.loc[:,'I_1_lag_20':'X_3_lag_0'].columns\n",
    "di=di.drop(to_drop,axis=1)\n",
    "dt=dt.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rangeons les variables par catégories\n",
    "# on essaiera d'intégrer différentes telles catégories de variables dans le modèle \n",
    "# il ne serait pas réaliste de vouloir tester toutes les combinaisons de variables, mais on peut les regrouper par type et essayer des combinaisons de catégories\n",
    "poids=['weight_I_1', 'weight_I_2', 'weight_I_3', 'weight_I_4', 'weight_I_5',\n",
    "       'weight_I_6', 'weight_I_7']\n",
    "last_perf=['L_1_lag_0','L_2_lag_0','L_3_lag_0','L_4_lag_0','L_5_lag_0','L_6_lag_0','L_7_lag_0']\n",
    "last_eco=['LX_1_lag_0', 'LX_2_lag_0', 'LX_3_lag_0']\n",
    "perf20=['M20_1', 'M20_2','M20_3', 'M20_4', 'M20_5', 'M20_6','M20_7']\n",
    "perf5=['M5_1', 'M5_2','M5_3', 'M5_4', 'M5_5', 'M5_6','M5_7']\n",
    "perfeco20=['LX20_1', 'LX20_2', 'LX20_3']\n",
    "perfeco5=[ 'LX5_1', 'LX5_2', 'LX5_3']\n",
    "perf5decal=['M5_1_1', 'M5_1_2', 'M5_1_3', 'M5_1_4', 'M5_1_5',\n",
    "       'M5_1_6', 'M5_1_7', 'R1', 'M5_2_1', 'M5_2_2', 'M5_2_3', 'M5_2_4',\n",
    "       'M5_2_5', 'M5_2_6', 'M5_2_7', 'R2', 'M5_3_1', 'M5_3_2', 'M5_3_3',\n",
    "       'M5_3_4', 'M5_3_5', 'M5_3_6', 'M5_3_7']\n",
    "spond=['sharpe','vol','R0']\n",
    "rendwdec=['R1','R2','R3']\n",
    "sharpdec=['sharpe1','sharpe2','sharpe3']\n",
    "covstrat=['covL_1_1',\n",
    "       'covL_1_2', 'covL_1_3', 'covL_1_4', 'covL_1_5', 'covL_1_6', 'covL_1_7',\n",
    "       'covL_2_1', 'covL_2_2', 'covL_2_3', 'covL_2_4', 'covL_2_5', 'covL_2_6',\n",
    "       'covL_2_7', 'covL_3_1', 'covL_3_2', 'covL_3_3', 'covL_3_4', 'covL_3_5',\n",
    "       'covL_3_6', 'covL_3_7', 'covL_4_1', 'covL_4_2', 'covL_4_3', 'covL_4_4',\n",
    "       'covL_4_5', 'covL_4_6', 'covL_4_7', 'covL_5_1', 'covL_5_2', 'covL_5_3',\n",
    "       'covL_5_4', 'covL_5_5', 'covL_5_6', 'covL_5_7', 'covL_6_1', 'covL_6_2',\n",
    "       'covL_6_3', 'covL_6_4', 'covL_6_5', 'covL_6_6', 'covL_6_7', 'covL_7_1',\n",
    "       'covL_7_2', 'covL_7_3', 'covL_7_4', 'covL_7_5','covL_7_6', 'covL_7_7']\n",
    "covXL=['covXI_1_1', 'covXI_1_2', 'covXI_1_3', 'covXI_1_4', 'covXI_1_5',\n",
    "       'covXI_1_6', 'covXI_1_7', 'covXI_2_1', 'covXI_2_2', 'covXI_2_3',\n",
    "       'covXI_2_4', 'covXI_2_5', 'covXI_2_6', 'covXI_2_7', 'covXI_3_1',\n",
    "       'covXI_3_2', 'covXI_3_3', 'covXI_3_4', 'covXI_3_5', 'covXI_3_6',\n",
    "       'covXI_3_7']\n",
    "covXX=['covX_1_1', 'covX_1_2', 'covX_1_3', 'covX_2_1', 'covX_2_2',\n",
    "       'covX_2_3', 'covX_3_1', 'covX_3_2', 'covX_3_3']\n",
    "sharps=[ 'sha_1', 'sha_2',\n",
    "       'sha_3', 'sha_4', 'sha_5', 'sha_6', 'sha_7']\n",
    "lagged_perf=['L_1_lag_1', 'L_1_lag_2',\n",
    "       'L_1_lag_3', 'L_1_lag_4', 'L_1_lag_5', 'L_1_lag_6', 'L_1_lag_7',\n",
    "       'L_1_lag_8', 'L_1_lag_9', 'L_1_lag_10', 'L_1_lag_11', 'L_1_lag_12',\n",
    "       'L_1_lag_13', 'L_1_lag_14', 'L_1_lag_15', 'L_1_lag_16', 'L_1_lag_17',\n",
    "       'L_1_lag_18', 'L_1_lag_19', 'L_2_lag_1', 'L_2_lag_2',\n",
    "       'L_2_lag_3', 'L_2_lag_4', 'L_2_lag_5', 'L_2_lag_6', 'L_2_lag_7',\n",
    "       'L_2_lag_8', 'L_2_lag_9', 'L_2_lag_10', 'L_2_lag_11', 'L_2_lag_12',\n",
    "       'L_2_lag_13', 'L_2_lag_14', 'L_2_lag_15', 'L_2_lag_16', 'L_2_lag_17',\n",
    "       'L_2_lag_18', 'L_2_lag_19',  'L_3_lag_1', 'L_3_lag_2',\n",
    "       'L_3_lag_3', 'L_3_lag_4', 'L_3_lag_5', 'L_3_lag_6', 'L_3_lag_7',\n",
    "       'L_3_lag_8', 'L_3_lag_9', 'L_3_lag_10', 'L_3_lag_11', 'L_3_lag_12',\n",
    "       'L_3_lag_13', 'L_3_lag_14', 'L_3_lag_15', 'L_3_lag_16', 'L_3_lag_17',\n",
    "       'L_3_lag_18', 'L_3_lag_19',  'L_4_lag_1', 'L_4_lag_2',\n",
    "       'L_4_lag_3', 'L_4_lag_4', 'L_4_lag_5', 'L_4_lag_6', 'L_4_lag_7',\n",
    "       'L_4_lag_8', 'L_4_lag_9', 'L_4_lag_10', 'L_4_lag_11', 'L_4_lag_12',\n",
    "       'L_4_lag_13', 'L_4_lag_14', 'L_4_lag_15', 'L_4_lag_16', 'L_4_lag_17',\n",
    "       'L_4_lag_18', 'L_4_lag_19', 'L_5_lag_1', 'L_5_lag_2',\n",
    "       'L_5_lag_3', 'L_5_lag_4', 'L_5_lag_5', 'L_5_lag_6', 'L_5_lag_7',\n",
    "       'L_5_lag_8', 'L_5_lag_9', 'L_5_lag_10', 'L_5_lag_11', 'L_5_lag_12','L_5_lag_13', 'L_5_lag_14', 'L_5_lag_15', 'L_5_lag_16', 'L_5_lag_17',\n",
    "       'L_5_lag_18', 'L_5_lag_19',  'L_6_lag_1', 'L_6_lag_2',\n",
    "       'L_6_lag_3', 'L_6_lag_4', 'L_6_lag_5', 'L_6_lag_6', 'L_6_lag_7',\n",
    "       'L_6_lag_8', 'L_6_lag_9', 'L_6_lag_10', 'L_6_lag_11', 'L_6_lag_12',\n",
    "       'L_6_lag_13', 'L_6_lag_14', 'L_6_lag_15', 'L_6_lag_16', 'L_6_lag_17',\n",
    "       'L_6_lag_18', 'L_6_lag_19',  'L_7_lag_1', 'L_7_lag_2',\n",
    "       'L_7_lag_3', 'L_7_lag_4', 'L_7_lag_5', 'L_7_lag_6', 'L_7_lag_7',\n",
    "       'L_7_lag_8', 'L_7_lag_9', 'L_7_lag_10', 'L_7_lag_11', 'L_7_lag_12',\n",
    "       'L_7_lag_13', 'L_7_lag_14', 'L_7_lag_15', 'L_7_lag_16', 'L_7_lag_17',\n",
    "       'L_7_lag_18', 'L_7_lag_19']\n",
    "lagged_eco=['LX_1_lag_1', 'LX_1_lag_2',\n",
    "       'LX_1_lag_3', 'LX_1_lag_4', 'LX_1_lag_5', 'LX_1_lag_6', 'LX_1_lag_7',\n",
    "       'LX_1_lag_8', 'LX_1_lag_9', 'LX_1_lag_10', 'LX_1_lag_11', 'LX_1_lag_12',\n",
    "       'LX_1_lag_13', 'LX_1_lag_14', 'LX_1_lag_15', 'LX_1_lag_16',\n",
    "       'LX_1_lag_17', 'LX_1_lag_18', 'LX_1_lag_19', 'LX_2_lag_1',\n",
    "       'LX_2_lag_2', 'LX_2_lag_3', 'LX_2_lag_4', 'LX_2_lag_5', 'LX_2_lag_6',\n",
    "       'LX_2_lag_7', 'LX_2_lag_8', 'LX_2_lag_9', 'LX_2_lag_10', 'LX_2_lag_11',\n",
    "       'LX_2_lag_12', 'LX_2_lag_13', 'LX_2_lag_14', 'LX_2_lag_15',\n",
    "       'LX_2_lag_16', 'LX_2_lag_17', 'LX_2_lag_18', 'LX_2_lag_19',\n",
    "       'LX_3_lag_1', 'LX_3_lag_2', 'LX_3_lag_3', 'LX_3_lag_4',\n",
    "       'LX_3_lag_5', 'LX_3_lag_6', 'LX_3_lag_7', 'LX_3_lag_8', 'LX_3_lag_9',\n",
    "       'LX_3_lag_10', 'LX_3_lag_11', 'LX_3_lag_12','LX_3_lag_13', 'LX_3_lag_14', 'LX_3_lag_15', 'LX_3_lag_16',\n",
    "       'LX_3_lag_17', 'LX_3_lag_18', 'LX_3_lag_19']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passons à la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il faut fabriquer notre propre CrossVal en tirant au sort une répartition entre train et test pour les séquences temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les LX20_1 semblent permettre de distinguer les séquences, dont on sait qu'elles sont de l'ordre de 10k/500=200\n",
    "# on va tirer au sort le train et le test en séparant par valeur de LX20_1\n",
    "sequences=di.LX20_1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# après plusieurs essais et erreur je retient cette combinaison (une encore meilleure donne un score public de 0.5273)\n",
    "malist=sharps+perf20+perfeco20+sharpdec+covXX+['sharpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1.0728281113968259\n",
      "0.6114937748713354\n",
      "0.536615902887003\n",
      "\n",
      "allcol\n",
      "training mae 0.556\n",
      "test mae 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.524\n",
      "test mae 0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.536\n",
      "test mae 0.489\n",
      "somecol\n",
      "training mae 0.500\n",
      "test mae 0.505\n",
      "somecol\n",
      "training mae 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae 0.505\n",
      "somecol\n",
      "training mae 0.459\n",
      "test mae 0.515\n",
      "somecol\n",
      "training mae 0.513\n",
      "test mae 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "1.3980251948886233\n",
      "0.6056276930348641\n",
      "0.5693866251107395\n",
      "\n",
      "allcol\n",
      "training mae 0.549\n",
      "test mae 0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.509\n",
      "test mae 0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.508\n",
      "test mae 0.594\n",
      "somecol\n",
      "training mae 0.488\n",
      "test mae 0.558\n",
      "somecol\n",
      "training mae 0.488\n",
      "test mae 0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.452\n",
      "test mae 0.561\n",
      "somecol\n",
      "training mae 0.499\n",
      "test mae 0.561\n",
      "21\n",
      "1.264221130804123\n",
      "0.5983490197159749\n",
      "0.5835183592005476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allcol\n",
      "training mae 0.552\n",
      "test mae 0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.518\n",
      "test mae 0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.514\n",
      "test mae 0.546\n",
      "somecol\n",
      "training mae 0.485\n",
      "test mae 0.531\n",
      "somecol\n",
      "training mae 0.485\n",
      "test mae 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.448\n",
      "test mae 0.546\n",
      "somecol\n",
      "training mae 0.500\n",
      "test mae 0.531\n",
      "42\n",
      "1.3978871996296465\n",
      "0.5811363545156293\n",
      "0.6428518282758011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allcol\n",
      "training mae 0.540\n",
      "test mae 0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.494\n",
      "test mae 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.491\n",
      "test mae 0.599\n",
      "somecol\n",
      "training mae 0.466\n",
      "test mae 0.593\n",
      "somecol\n",
      "training mae 0.464\n",
      "test mae 0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somecol\n",
      "training mae 0.433\n",
      "test mae 0.594\n",
      "somecol\n",
      "training mae 0.474\n",
      "test mae 0.593\n",
      "               2        12        21        42   moyenne\n",
      "Bench   0.611494  0.605628  0.598349  0.581136  0.599152\n",
      "Elast0  0.556058  0.549028  0.552425  0.539783  0.549323\n",
      "rf2     0.523888  0.509101  0.518417  0.494060  0.511366\n",
      "rf0     0.535746  0.507691  0.514222  0.490910  0.512142\n",
      "Lgb0    0.500000  0.488355  0.484671  0.465561  0.484647\n",
      "Lgb1    0.500000  0.488355  0.484671  0.464278  0.484326\n",
      "Lgb2    0.458621  0.452111  0.448271  0.432669  0.447918\n",
      "Lgb3    0.512837  0.498789  0.500481  0.474242  0.496587\n",
      "               2        12        21        42   moyenne\n",
      "Bench   0.536616  0.569387  0.583518  0.642852  0.583093\n",
      "Elast0  0.547843  0.559148  0.558916  0.588585  0.563623\n",
      "rf2     0.493120  0.559180  0.545533  0.585966  0.545950\n",
      "rf0     0.489313  0.593698  0.546319  0.598639  0.556993\n",
      "Lgb0    0.504520  0.558243  0.531234  0.592669  0.546667\n",
      "Lgb1    0.504520  0.558243  0.531234  0.591228  0.546306\n",
      "Lgb2    0.515049  0.560532  0.545732  0.593627  0.553735\n",
      "Lgb3    0.502705  0.561068  0.531116  0.593092  0.546995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "Napo=pd.DataFrame(\n",
    "      {'Bench' : [0,0,0,0]\n",
    "        },\n",
    "    index=[2,12,21,42] )\n",
    "Napo=Napo.T\n",
    "\n",
    "NapoT=pd.DataFrame(\n",
    "      {'Bench' : [0,0,0,0]\n",
    "        },\n",
    "    index=[2,12,21,42] )\n",
    "NapoT=NapoT.T\n",
    "\n",
    "\n",
    "for rs in [2, 12, 21, 42]:\n",
    "    n_train, n_val =train_test_split(sequences,random_state=rs)\n",
    "    l_train=n_train.tolist()\n",
    "    l_val=n_val.tolist()\n",
    "    # construisons les échantillons en fonction de ces dates\n",
    "    Z=di\n",
    "    Z['custom']=do['custom']\n",
    "    Z['Target']=do['Target']\n",
    "    X_train=Z[Z.LX20_1.isin(l_train)]\n",
    "    X_test=Z[Z.LX20_1.isin(l_val)]\n",
    "    # nous devons aussi sélectionner les y correspondant à ces train et tests\n",
    "    y_train=X_train[['Target','custom']]\n",
    "    y_test=X_test[['Target','custom']]\n",
    "    X_train=X_train.drop(['custom','Target'],axis=1)\n",
    "    X_test=X_test.drop(['custom','Target'],axis=1)\n",
    "    \n",
    "    ## cherchons à reproduire le benchmark\n",
    "    model='Bench'\n",
    "    a=y_train.Target.mean()\n",
    "    print(rs)\n",
    "    print(a)\n",
    "    X_train['ebench']=np.sign(a)*np.exp(-1/(abs(a)))\n",
    "    X_test['ebench']=np.sign(a)*np.exp(-1/(abs(a)))\n",
    "    print(mean_absolute_error(y_train.custom, X_train.ebench))\n",
    "    print(mean_absolute_error(y_test.custom, X_test.ebench))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, X_test.ebench)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, X_train.ebench)\n",
    "    X_train=X_train.drop('ebench',axis=1)\n",
    "    X_test=X_test.drop('ebench',axis=1)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # normalisons pour les méthodes linéaires\n",
    "    scaler=StandardScaler()\n",
    "    d_train=scaler.fit_transform(X_train)\n",
    "    d_train= pd.DataFrame(d_train, columns=X_train.columns)\n",
    "    #scalons les données de test sur l'échelle d'apprentissage\n",
    "    d_test=scaler.transform(X_test)\n",
    "    d_test = pd.DataFrame(d_test, columns=X_test.columns)\n",
    "      \n",
    "    \n",
    "    \n",
    "       \n",
    "    \n",
    "    # et avec moins de colonnes\n",
    "    some_col=malist\n",
    "    \n",
    "    d_r=d_train[some_col]\n",
    "    d_s=d_test[some_col]\n",
    "    \n",
    "    model='Elast0'\n",
    "    alpha=0.08\n",
    "    l1_ratio=0.05\n",
    "    reg = ElasticNet(alpha=alpha,l1_ratio=l1_ratio)\n",
    "    reg.fit(d_r,y_train.custom)\n",
    "    y_r=reg.predict(d_r)\n",
    "    y_s=reg.predict(d_s)\n",
    "    print('allcol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)  \n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)  \n",
    "    \n",
    "    \n",
    "       \n",
    "    X_r=X_train[some_col]\n",
    "    X_s=X_test[some_col]\n",
    "        \n",
    "    model='rf2'\n",
    "    k=2\n",
    "    rtr=RandomForestRegressor(max_depth=k,max_features=15, criterion=\"mae\",random_state=rs)\n",
    "    rtr.fit(X_r,y_train.custom)\n",
    "    #sappr=rtr.score(X_r,y_train.custom)\n",
    "    #stest=rtr.score(X_s,y_test.custom)\n",
    "    y_r=rtr.predict(X_r)\n",
    "    y_s=rtr.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)\n",
    "    \n",
    "    model='rf0'\n",
    "    k=2\n",
    "    rtr=RandomForestRegressor(max_depth=k, criterion=\"mae\",random_state=rs)\n",
    "    rtr.fit(X_r,y_train.custom)\n",
    "    #sappr=rtr.score(X_r,y_train.custom)\n",
    "    #stest=rtr.score(X_s,y_test.custom)\n",
    "    y_r=rtr.predict(X_r)\n",
    "    y_s=rtr.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)\n",
    "    \n",
    "    model='Lgb0'\n",
    "    params={ \n",
    "    'max_depth': 2,\n",
    "    #'num_leaves': 300,\n",
    "    #'subsample_freq': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    #'n_estimators': 3000,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    'objective': 'regression_l1',\n",
    "    #'subsample': 0.9,\n",
    "    'reg_lambda': 0.01,\n",
    "    #'min_data_in_leaf':20\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(X_r, y_train.custom)\n",
    "    gbl = lgb.train(params,lgb_train)\n",
    "    y_r=gbl.predict(X_r)\n",
    "    y_s=gbl.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)  \n",
    "         \n",
    "      \n",
    "    model='Lgb1'\n",
    "    params={ \n",
    "    'max_depth': 2,\n",
    "    #'num_leaves': 20,\n",
    "    #'subsample_freq': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 100,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    'objective': 'regression_l1',\n",
    "    #'subsample': 0.9,\n",
    "    'reg_lambda': 0.1,\n",
    "    #'min_data_in_leaf':20\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(X_r, y_train.custom)\n",
    "    gbl = lgb.train(params,lgb_train)\n",
    "    y_r=gbl.predict(X_r)\n",
    "    y_s=gbl.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)\n",
    "    \n",
    "    model='Lgb2'\n",
    "    params={ \n",
    "    'max_depth': 2,\n",
    "    #'num_leaves': 10,\n",
    "    #'subsample_freq': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 200,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    'objective': 'regression_l1',\n",
    "    #'subsample': 0.9,\n",
    "    'reg_lambda': 0.1,\n",
    "    #'min_data_in_leaf':40\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(X_r, y_train.custom)\n",
    "    gbl = lgb.train(params,lgb_train)\n",
    "    y_r=gbl.predict(X_r)\n",
    "    y_s=gbl.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)\n",
    "    \n",
    "    model='Lgb3'\n",
    "    params={ \n",
    "    'max_depth': 2,\n",
    "    #'num_leaves': 300,\n",
    "    #'subsample_freq': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 80,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    'objective': 'regression_l1',\n",
    "    #'subsample': 0.9,\n",
    "    'reg_lambda': 0.1,\n",
    "    #'min_data_in_leaf':100\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(X_r, y_train.custom)\n",
    "    gbl = lgb.train(params,lgb_train)\n",
    "    y_r=gbl.predict(X_r)\n",
    "    y_s=gbl.predict(X_s)\n",
    "    print('somecol')\n",
    "    print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,y_train.custom)))\n",
    "    print(\"test mae {:.3f}\".format(mean_absolute_error(y_s,y_test.custom)))\n",
    "    Napo.loc[model,rs ]=mean_absolute_error(y_test.custom, y_s)\n",
    "    NapoT.loc[model,rs ]=mean_absolute_error(y_train.custom, y_r)\n",
    "    \n",
    "    \n",
    "NapoT['moyenne']=NapoT.mean(axis=1)\n",
    "print(NapoT)    \n",
    "Napo['moyenne']=Napo.mean(axis=1)\n",
    "print(Napo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Re<Calibrons sur tout l'échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_col=malist\n",
    "di1=di[some_col]\n",
    "dt1=dt[some_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mae 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "params={ \n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    'objective': 'regression_l1',\n",
    "    'reg_lambda': 0.01\n",
    "      }\n",
    "lgb_train = lgb.Dataset(di1, do.custom)\n",
    "gbl = lgb.train(params,lgb_train)\n",
    "y_r=gbl.predict(di1)\n",
    "y_s=gbl.predict(dt1)\n",
    "print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,do.custom)))\n",
    "dt1['fy']=y_s\n",
    "dt1['y']=-np.sign(dt1['fy'])/(np.log(abs(dt1['fy'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.y.to_csv('Napo2_Lgb2a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf465c5b70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf419d1630>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(gbl, max_num_features=20, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat 0.5428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1b=dt1.drop(['fy','y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mae 0.509\n"
     ]
    }
   ],
   "source": [
    "k=2\n",
    "rtr=RandomForestRegressor(max_depth=k, criterion=\"mae\",random_state=rs)\n",
    "rtr.fit(di1, do.custom)\n",
    "y_r=rtr.predict(di1)\n",
    "y_s=rtr.predict(dt1b)\n",
    "print(\"training mae {:.3f}\".format(mean_absolute_error(y_r,do.custom)))\n",
    "dt1b['fy']=y_s\n",
    "dt1b['y']=-np.sign(dt1b['fy'])/(np.log(abs(dt1b['fy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1b.y.to_csv('Napo2_RF2a2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Muller & Guido \n",
    "# https://github.com/amueller/introduction_to_ml_with_python/blob/master/02-supervised-learning.ipynb\n",
    "\n",
    "def plot_feature_importances(model, Frame):\n",
    "    plt.clf()\n",
    "    n_features=len(Frame.columns)\n",
    "    plt.grid()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), Frame.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-95b69b1afa58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#dt2=dt1.drop(['fy','y'],axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdt2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_feature_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-b7fa9aad7a0e>\u001b[0m in \u001b[0;36mplot_feature_importances\u001b[1;34m(model, Frame)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature importance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbarh\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2667\u001b[0m                       mplDeprecation)\n\u001b[0;32m   2668\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2669\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2670\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbarh\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2281\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'orientation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'horizontal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m         patches = self.bar(x=left, height=height, width=width,\n\u001b[1;32m-> 2283\u001b[1;33m                            bottom=y, **kwargs)\n\u001b[0m\u001b[0;32m   2284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2015\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0;32m   2016\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2017\u001b[1;33m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[0;32m   2018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'vertical'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\pc\\Anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf465eb080>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf474eb9e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dt2=dt1.drop(['fy','y'],axis=1)\n",
    "dt2=dt1\n",
    "plot_feature_importances(rtr, dt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat 0.5434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en faisant la moyenne des deux prévisions :\n",
    "dt1b['z']=(dt1b['y']+dt1['y'])/2\n",
    "dt1b.z.to_csv('Napo2_moy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat 0.539"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
